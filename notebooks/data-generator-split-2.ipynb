{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "from td_utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5511 # The number of time steps input to the model from the spectrogram\n",
    "Ty = 1375 # The number of time steps in the output of our model\n",
    "n_freq = 101 # Number of frequencies input to the model at each time step of the spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Sequence Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, `x_set` is list of path to the spectrogram .npy file\n",
    "# and `y_set` are the associated truth vector .npy file\n",
    "\n",
    "class SpectrogramDataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ''' this method should return a complete batch. '''\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return (np.array([np.load(filename) for filename in batch_x]),\n",
    "                np.array([np.load(filename) for filename in batch_y]))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        ''' If you want to modify your dataset between epochs you may implement. '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_filenames = sorted(glob.glob('../data/dev_set/x_spectrogram_*.npy'))\n",
    "y_filenames = sorted(glob.glob('../data/dev_set/y_*.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples = 10000\n",
      "../data/dev_set/x_spectrogram_0.npy\n",
      "../data/dev_set/y_0.npy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples =', len(x_filenames))\n",
    "print(x_filenames[0])\n",
    "print(y_filenames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train/val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filename_train, X_filename_val, Y_filename_train, Y_filename_val = train_test_split(\n",
    "    x_filenames, y_filenames, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples = 8000\n",
      "../data/dev_set/x_spectrogram_9327.npy\n",
      "../data/dev_set/y_9327.npy\n",
      "../data/dev_set/x_spectrogram_7297.npy\n",
      "../data/dev_set/y_7297.npy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples =', len(X_filename_train))\n",
    "print(X_filename_train[0])\n",
    "print(Y_filename_train[0])\n",
    "\n",
    "print(X_filename_train[100])\n",
    "print(Y_filename_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = SpectrogramDataGenerator(X_filename_train, Y_filename_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 - X shape= (250, 5511, 101)\n",
      "batch 0 - y shape= (250, 1375, 1)\n"
     ]
    }
   ],
   "source": [
    "batch0_X, batch0_y = training_generator.__getitem__(0)\n",
    "\n",
    "print('batch 0 - X shape=', batch0_X.shape)\n",
    "print('batch 0 - y shape=', batch0_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = SpectrogramDataGenerator(X_filename_val, Y_filename_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 - X shape= (250, 5511, 101)\n",
      "batch 0 - y shape= (250, 1375, 1)\n"
     ]
    }
   ],
   "source": [
    "batch0_X, batch0_y = val_generator.__getitem__(0)\n",
    "\n",
    "print('batch 0 - X shape=', batch0_X.shape)\n",
    "print('batch 0 - y shape=', batch0_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "\n",
    "The model will use 1-D convolutional layers, GRU layers, and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gru(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CONV layer\n",
    "    X = Conv1D(196, 15, strides=4)(X_input)  # CONV1D\n",
    "    X = BatchNormalization()(X)              # Batch normalization\n",
    "    X = Activation('relu')(X)                # ReLu activation\n",
    "    #X = Dropout(0.8)(X)                      # dropout \n",
    "\n",
    "    # First GRU Layer\n",
    "    X = GRU(128, return_sequences=True)(X)   # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.5)(X)                      # dropout\n",
    "    X = BatchNormalization()(X)              # Batch normalization\n",
    "    \n",
    "    # Second GRU Layer\n",
    "    X = GRU(128, return_sequences=True)(X)   # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.5)(X)                      # dropout \n",
    "    X = BatchNormalization()(X)              # Batch normalization\n",
    "    X = Dropout(0.5)(X)                      # dropout \n",
    "    \n",
    "    # Time-distributed dense layer\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gru(input_shape = (Tx, n_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 181s - loss: 1.2026 - acc: 0.5261 - val_loss: 1.1040 - val_acc: 0.4837\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 165s - loss: 1.0850 - acc: 0.5683 - val_loss: 1.0017 - val_acc: 0.6232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c3e0a6278>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    epochs=2,\n",
    "\n",
    "    generator=training_generator,\n",
    "    steps_per_epoch=len(training_generator),\n",
    " \n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "rSupZ",
   "launcher_item_id": "cvGhe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
